---
title: "Estrategias evolutivas"
output: html_notebook
---


# Introducción

Los algoritmos del área de la computación evolutiva tratan de resolver problemas de diversa índole sin que se necesite asumir demasiadas hipótesis para su aplicación. Los algoritmos más clásicos de métodos numéricos para la resolución de problemas de optimización suelen tener unas hipótesis asociadas que en la práctica son difíciles de cumplir. Por ejemplo, el algoritmo del descenso del gradiente exige que la función sobre la que se aplique sea diferenciable. Otras hipótesis pueden ser la concavidad o convexidad, continuidad, problemas con los mínimos o máximos locales, etcétera. 

Sin embargo, en funciones que pueden ser muy complejas o en problemas en los que se modelice la realidad, es frecuente que estas hipótesis no puedan aplicarse y, por tanto, haya que buscar algoritmos lo más *agnósticos* posibles. Es el caso de las estrategias evolutivas. 

# Definición del problema

El objetivo es el de evaluar el comportamiento de estrategias evolutivas en la optimización de:

- **función suma de powell**.
- **función Nº4 de Xin-She Yang**.

Estas dos funciones son lo suficientemente complejas como para que no se puedan aplicar algoritmos habituales de métodos numéricos.

## Función suma de Powell

La función suma de Powel está definida por la expresión

$$
f(\bar{x}) = \sum_{i = 1}^n |x_i|^{i+1}
$$

donde $\bar{x} = (x_1, x_2, \ldots, x_n)$, siendo $-1 \leq x_i \leq 1$, $i = 1, \ldots,n$. Esta función tiene como propiedades ser:

- multi-dimensional
- continua
- convexa
- no-diferenciable
- unimodal

Podemos representar la función en el caso en el que $\bar{x} \in \mathbb{R}^2$.

```{r echo=FALSE}
library(plot3D)
source("funciones_a_optimizar.R")

x <- seq(-1, 1, length.out=50)
y <- x
M <- mesh(x, y)

alpha <- M$x
beta <- M$y

a <- cbind(as.vector(alpha), as.vector(beta))

z <- apply(a, 1, suma_powell)

b <- matrix(z, nrow = 50, ncol = 50)

par(mfrow = c(1, 2))
surf3D(x      = alpha,
       y      = beta,
       z      = b,
       colkey = FALSE,
       bty    = "b2",
       main   = "Función suma de Powell ",
       theta = 90)

surf3D(x      = alpha,
       y      = beta,
       z      = b,
       #colkey = FALSE,
       bty    = "b2",
       #main   = "Función suma de Powell ",
       theta = 90,
       phi = 0)
par(mfrow = c(1, 1))
```

Esta función presenta un mínimo global que se alcanza en $\bar{x}^* = (0,0)$ tomando $f(\bar{x}^* ) = 0$.

## Función Nº 4 de Xin-She Yang

La función Nº 4 de Xin-She Yang tiene como expresión

$$
f(\bar{x}) = \left( \sum_{i=1}^n sin^2(x_i) - exp\left(-\sum_{i=1}^nx_i^2\right)\right)\cdot exp\left(-\sum_{i=1}^nsin^2(\sqrt{|x_i|})\right)
$$

Esta función es:

- No convexa.
- No diferenciable.


```{r echo=FALSE}

x <- seq(-10, 10, length.out=50)
y <- x
M <- mesh(x, y)

alpha <- M$x
beta <- M$y

a <- cbind(as.vector(alpha), as.vector(beta))

z <- apply(a, 1, xin_she_yang_4)

b <- matrix(z, nrow = 50, ncol = 50)

par(mfrow = c(1, 2))
surf3D(x      = alpha,
       y      = beta,
       z      = b,
       colkey = FALSE,
       bty    = "b2",
       main   = "Función suma de Powell ")

surf3D(x      = alpha,
       y      = beta,
       z      = b,
       colkey = FALSE,
       bty    = "b2",
       #main   = "Función Nº 4 de Xin-She Yang",
       theta = 90,
       phi = 0)
par(mfrow = c(1, 1))
```


En el caso de $\mathbb{R}^2$, se ve que existe una gran cantidad de mínimos locales pero solo un mínimo global que se alcanza en $\bar{x}^* = (0,0)$ tomando $f(\bar{x}^* ) = -1$.

# Descripción de Estrategia Evolutiva

# Implementación


# Discusión de resultados

A continuación se detallan los resultados obtenidos al aplicar los algoritmos de estrategias evolutivas sobre las funciones de suma de Powell y la Nº 4 de Xin-She Yang.

Ambas funciones se atacarán sobre un espacio de dimensión $5$, es decir, se tratará de resolver el problema
$$
argmin \,f(\bar{x})
$$

tal que $\bar{x} = (x_1, \ldots, x_5)$.

Las estrategias evolutivas, como la gran mayoría del algoritmos utilizados para la optimización, llevan asociadas una serie de parámetros y configuraciones que pueden cambiar, por ejemplo, la eficiencia con la que se resuelva el problema. En nuestro caso, se va a abordar el problema con las siguientes configuraciones:

- **Configuración 1:**
    - *Tipo de mutación:* no correlacionada de paso único.
    - *Selección de supervivientes*: $(\mu, \lambda) = (30, 200)$
- **Configuración 2:**
    - *Tipo de mutación:* no correlacionada de $n$ pasos.
    - *Selección de supervivientes*: $(\mu, \lambda) = (30, 200)$
- **Configuración 3:**
    - *Tipo de mutación:* no correlacionada de paso único.
    - *Selección de supervivientes*: $(\mu + \lambda) = (30 + 200)$
- **Configuración 4:**
    - *Tipo de mutación:* no correlacionada de $n$ pasos.
    - *Selección de supervivientes*: $(\mu + \lambda) = (30 + 200)$

Todas las configuraciones tendrán en común:

- $20$ ejecuciones independientes del algoritmo.
- $1000$ generaciones en cada ejecución.

Por supuesto, hay más parámetros que pueden intervenir en las estrategias evolutivas y que serán tratados también las ejecuciones.

## Función suma de Powell

### Configuración 1

Para esta ejecución, es necesario ejecutar el siguiente código conforme a la implementación realizada:

```{r, eval=FALSE}
param <- list(n.x = 5,
              n.sigma = 1,
              tam.poblacion = 30,
              
              x.min = -1,
              x.max = 1,
              
              sigma.min = 1,
              sigma.max = 10,
              
              num.iter = 1000,
              
              lambda = 200,
              mu = 30,
              estrategia = ",",
              min = TRUE,
              funcion = suma_powell,
              
              global = TRUE,
              recomb.x = "discreta",
              recomb.sigma = "discreta",
              
              tau1 = 1/sqrt(2*5),
              tau2 = 0,
              epsilon = 0.001
)

set.seed(123)
resultados <- replicate(20, estrategia_evolutiva(param), simplify = FALSE)  
```


A continuación se muestra la **gráfica de progreso** obtenida de la ejecución del algoritmo, es decir, se representa una línea para cada una de las $20$ ejecuciones que pueda relacionar el menor valor de la función de fitness obtenido en cada iteración:

```{r echo=FALSE}
source("R/graficos.R")

resultados <- readRDS("resultados/powell_3_,")
resultados <- grafico_progreso(resultados)
resultados %>%
  #filter(iteracion <= 20) %>%
  ggplot(aes(x = iteracion,
             y = fitness,
             group = id_ejecucion)) +
  geom_line() + 
  labs(caption = "Gráfico de progreso",
       x = "Iteración",
       title = "Gráfico de progreso para la configuración 1")
```

A la vista de este gráfico, se aprecia una disminución de la función de fitness bastante acusada en las primeras iteraciones. Sin embargo, la escala del gráfico dificulta obtener conclusiones. Si hacemos *zoom* sobre las 20 primeras iteraciones del algoritmo, comprobamos el abrupto descenso que sucede en las diez primeras.

```{r}
resultados %>%
  filter(iteracion <= 20) %>%
  ggplot(aes(x = iteracion,
             y = fitness,
             group = id_ejecucion)) +
  geom_line() + 
  labs(caption = "Gráfico de progreso",
       x = "Iteración",
       title = "Gráfico de progreso para la configuración 1", 
       subtitle = "Restringido a las 20 primeras iteraciones")
```




# ```{r}
# resultados %>%
#   filter(iteracion > 20, iteracion < 50) %>%
#   ggplot(aes(x = iteracion,
#              y = fitness,
#              group = id_ejecucion)) +
#   geom_line() + 
#   labs(caption = "Gráfico de progreso")
# ```

<!-- En la representación del progreso de la iteración $20$ hasta la $50$, el algoritmo comienza a comportarse de manera herrática, comportamiento que también suede si representamos de la iteración $20$ hasta las 1000  -->

<!-- ```{r} -->
<!-- resultados %>% -->
<!--   filter(iteracion > 50) %>% -->
<!--   ggplot(aes(x = iteracion, -->
<!--              y = fitness, -->
<!--              group = id_ejecucion)) + -->
<!--   geom_line() +  -->
<!--   labs(caption = "Gráfico de progreso") -->
<!-- ``` -->

Para obtener una mejor visión del problema, vamos a representar la ganancia porcentual entre dos iteraciones, es decir,

$$
ganacia(i) = \frac{f_i - f_{i-1}}{f_{i-1}}
$$
siendo $f_i$ el mínimo valor de la función de fitness obtenido en la iteración $i$-ésima.

Si representamos esta función para las primeras $50$ iteraciones, obtenemos el siguiente gráfico

```{r echo=FALSE, message=FALSE, warning=FALSE}
resultados %>% 
  group_by(id_ejecucion) %>% 
  mutate(inc_fitness = abs(fitness - lag(fitness))/lag(fitness)) %>% 
  filter(iteracion <= 50) %>%
  ggplot(aes(x = iteracion,
             y = inc_fitness
             )) +
  geom_line(aes(group = id_ejecucion), alpha = 0.4) + 
  geom_smooth(color = "firebrick") +
  labs(caption = "Gráfico de progreso",
       x = "Iteración",
       y = "Ganancia")
```

Se aprecia una ganancia en torno al $50%$ en las $20$ primeras iteraciones para luego convertirse en un patrón ruidoso, una posible señal de que el algoritmo ha dejado de ser capaz de realizar una mejora clara de la solución anterior y de ahí ese comportamiento errático.

En un problema en el que desconocemos las características de la función de *fitness* que queremos optimizar, es imposible poder saber lo precisa que es la solución propuesta. Sin embargo, en nuestro caso conocemos las propiedades de la función suma de Powell, en particular sabemos que el mínimo se alcanza en $\bar{x}^* = \bar{0}$ siendo $f(\bar{x}^*) = 0$. Por lo tanto, esto nos sirve para saber **cómo de próxima es la solución obtenida a la solución real y poder definir un umbral de error para el que podemos considerar que el problema ha sido resuelto**. La decisión del umbral es completamente arbitraria y dependerá del problema que se tenga entre manos. Por supuesto, cuanto menor sea la tolerancia permitida, más tardará el algoritmo en satisfacer la condición. Para este estudio **consideraremos que el algoritmo ha solucionado el problema cuando se obtenga que $|f(x)| \leq 10^{-10}$.** Con este umbral obtenemos los siguientes estadísticos


```{r message=FALSE, warning=FALSE}
res <- resultados %>% 
  group_by(id_ejecucion) %>% 
  filter(fitness < 10**-7) %>% 
  top_n(1, wt = fitness) 

res %>% 
  ungroup() %>% 
  summarise(min = min(iteracion),
            media = mean(iteracion),
            mediana = median(iteracion),
            max = max(iteracion),
            desviacion_estandar = sd(iteracion))
```

En media, el algoritmo tarda $537.25$ iteraciones en alcanzar la solución al problema aunque con una desviación típica amplia, de $280.0336$ iteraciones. Podemos visualizar esta información como:

```{r}
res %>% 
  ggplot(aes(x = iteracion, y = fitness)) + 
  geom_point()
```

Una métrica útil para describir el comportamiento del algoritmo es el **ratio de éxito** o **SR** (*success rate* por sus siglas en inglés), es decir, de las ejecuciones realizadas, **en cuántas se obtiene un valor por debajo del umbral de error**. Con el umbral definido de $10^{-10}$, en nuestro caso se obtienen

```{r}
res
```


### Mutación no correlacionada de n pasos

```{r}
resultados <- readRDS("resultados/powell_4_,")
resultados <- grafico_progreso(resultados)
resultados %>%
  #filter(iteracion <= 20) %>%
  ggplot(aes(x = iteracion,
             y = fitness,
             group = id_ejecucion)) +
  geom_line() + 
  labs(caption = "Gráfico de progreso")
```


## Función Nº 4 de Xin-She Yang


# Discusión

Las estrategias evolutivas nos sirven para resolver problemas complejos. No obstante, si la función o el problema a optimizar cumple las hipótesis de estos algoritmos, estos tendrán un comportamiento mejor que el que pueda tener una estrategia evolutiva puesto que se aprovechan de la estructura de la función para mejorar el proceso de optimización. Por ello, hay que tener en cuenta la naturaleza del problema que se tiene entre manos para saber qué tipo de algoritmo sería el adecuado.